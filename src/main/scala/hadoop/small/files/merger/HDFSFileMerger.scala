/*
 * This Scala source file was generated by the Gradle 'init' task.
 */
package hadoop.small.files.merger

import java.util.Calendar

import com.databricks.spark.avro._
import hadoop.small.files.merger.utils.{CommandLineArgs, CommandLineArgsParser, HDFSUtils}
import org.apache.spark.sql.SparkSession


object HDFSFileMerger extends App {
  val hdfsUtils = new HDFSUtils()
  val commandLine = new CommandLineArgsParser(hdfsUtils)

  commandLine
    .parser
    .parse(args, new CommandLineArgs) match {
    case Some(config) => {
      val blockSize = config.blockSize

      val sparkSession: SparkSession = SparkSession.builder().getOrCreate()
      if (config.format.equalsIgnoreCase("avro")) {
        val schema = commandLine.getSchemaString(config)
        if (config.fromDate != null && config.toDate != null) {
          println(s"From Date: ${config.fromDate}, To: ${config.toDate}")
          (config.fromDate.getTimeInMillis to config.toDate.getTimeInMillis)
            .by(86400000)
            .foreach(dayEpoch => {

              val date = Calendar.getInstance()
              date.setTimeInMillis(dayEpoch)
              val fullDirectoryPath = commandLine.getDatePartitionedPath(config, date)

              if (hdfsUtils.exists(fullDirectoryPath)) {
                val directorySize = hdfsUtils.getDirectorySize(fullDirectoryPath)

                val partitionSize = if (directorySize <= blockSize) 1 else Math.ceil(directorySize / blockSize).toInt
                println(s"Directory Size: ${directorySize}")
                println(s"Number of Partitions: ${partitionSize}")
                println(fullDirectoryPath)


                sparkSession
                  .read
                  .option("avroSchema", schema)
                  .avro(fullDirectoryPath)
                  .repartition(partitionSize)
                  .write
                  .avro(s"${fullDirectoryPath}_merged")

                if (hdfsUtils.renameDir(fullDirectoryPath, s"${fullDirectoryPath}_bak")) {
                  println("Source Directory renamed")
                  if (hdfsUtils.renameDir(s"${fullDirectoryPath}_merged", fullDirectoryPath)) {
                    println("Merged Directory renamed")
                    if (hdfsUtils.moveToTrash(s"${fullDirectoryPath}_bak")) {
                      println(s"Moved ${fullDirectoryPath}_bak to trash")
                    }
                  }
                }


              }
            })
        }


      }

    }
    case _ => commandLine.parser.renderTwoColumnsUsage
  }


}
